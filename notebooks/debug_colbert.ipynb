{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8260c87b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/accounts/projects/sewonm/prasann/.conda/envs/scaling2/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# figure out what's going on with ColBERT scores\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pylate.utils.tensor import convert_to_tensor\n",
    "\n",
    "\n",
    "def colbert_scores(\n",
    "    queries_embeddings: list | np.ndarray | torch.Tensor,\n",
    "    documents_embeddings: list | np.ndarray | torch.Tensor,\n",
    "    queries_mask: torch.Tensor = None,\n",
    "    documents_mask: torch.Tensor = None,\n",
    ") -> torch.Tensor:\n",
    "\n",
    "    queries_embeddings = convert_to_tensor(queries_embeddings)\n",
    "    documents_embeddings = convert_to_tensor(documents_embeddings)\n",
    "\n",
    "    scores = torch.einsum(\n",
    "        \"ash,bth->abst\",\n",
    "        queries_embeddings,\n",
    "        documents_embeddings,\n",
    "    )\n",
    "\n",
    "    if queries_mask is not None:\n",
    "        queries_mask = convert_to_tensor(queries_mask)\n",
    "        scores = scores * queries_mask.unsqueeze(1).unsqueeze(3)\n",
    "\n",
    "    if documents_mask is not None:\n",
    "        documents_mask = convert_to_tensor(documents_mask)\n",
    "        scores = scores * documents_mask.unsqueeze(0).unsqueeze(2)\n",
    "    scores = scores.max(axis=-1).values.max(axis=-1)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab0e5867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 1: No zero vectors - should match original behavior\n",
      "Shape: torch.Size([2]), Values: tensor([-0.6790, -0.1605])\n",
      "Manual calculation for batch 0: -0.6789754033088684\n",
      "Match: True\n",
      "\n",
      "Test 2: Some zero vectors\n",
      "Result: tensor([0.6667, 0.0000])\n",
      "Expected for batch 0: 0.6666666865348816\n",
      "Match: True\n",
      "\n",
      "Test 3: All zero vectors\n",
      "Result (should be zeros): tensor([0., 0.])\n",
      "All zeros: True\n",
      "\n",
      "Test 4: Only one non-zero vector per batch\n",
      "Result (should be zeros - no pairs): tensor([0., 0.])\n",
      "All zeros: True\n",
      "\n",
      "Test 5: T=1 edge case\n",
      "Result for T=1: tensor([0.])\n",
      "\n",
      "Test 6: Differentiability test\n",
      "Result: tensor([11.], grad_fn=<WhereBackward0>)\n",
      "Gradient shape: torch.Size([1, 3, 2])\n",
      "Gradient (should be non-zero for non-zero vectors):\n",
      "tensor([[[3., 4.],\n",
      "         [1., 2.],\n",
      "         [0., 0.]]])\n",
      "Zero vector gradient (should be zero): tensor([0., 0.])\n",
      "Is differentiable: True\n",
      "\n",
      "Test 7: Mixed scenario\n",
      "Result: tensor([0.6667])\n",
      "Expected: ~0.667\n",
      "Match: True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def compute_avg_pairwise_sim(embeddings):\n",
    "    B, T, D = embeddings.shape\n",
    "    if T == 1:\n",
    "        return torch.tensor([0.0])\n",
    "    \n",
    "    # Identify non-zero vectors (any non-zero element in last dim)\n",
    "    non_zero_mask = (embeddings.abs().sum(dim=-1) > 0)  # (B, T)\n",
    "    \n",
    "    # Compute similarity matrix\n",
    "    sim = embeddings @ embeddings.transpose(-1, -2)  # (B, T, T)\n",
    "    \n",
    "    # Create mask for valid pairs (both vectors non-zero, excluding diagonal)\n",
    "    valid_pairs = non_zero_mask.unsqueeze(-1) & non_zero_mask.unsqueeze(-2)  # (B, T, T)\n",
    "    valid_pairs = valid_pairs & ~torch.eye(T, dtype=bool, device=embeddings.device)\n",
    "    \n",
    "    # Count valid pairs per batch\n",
    "    num_valid = valid_pairs.sum(dim=(1, 2))  # (B,)\n",
    "    \n",
    "    # Sum similarities for valid pairs\n",
    "    masked_sim = torch.where(valid_pairs, sim, torch.zeros_like(sim))\n",
    "    sum_sim = masked_sim.sum(dim=(1, 2))  # (B,)\n",
    "    \n",
    "    # Compute average, handling case where no valid pairs exist\n",
    "    avg_sim = torch.where(num_valid > 0, sum_sim / num_valid, torch.zeros_like(sum_sim))\n",
    "    \n",
    "    return avg_sim\n",
    "\n",
    "\n",
    "def test_compute_avg_pairwise_sim():\n",
    "    print(\"Test 1: No zero vectors - should match original behavior\")\n",
    "    embeddings = torch.randn(2, 4, 8)\n",
    "    result = compute_avg_pairwise_sim(embeddings)\n",
    "    print(f\"Shape: {result.shape}, Values: {result}\")\n",
    "    \n",
    "    # Manual verification for first batch\n",
    "    sim = embeddings[0] @ embeddings[0].T\n",
    "    manual = sim[~torch.eye(4, dtype=bool)].mean()\n",
    "    print(f\"Manual calculation for batch 0: {manual}\")\n",
    "    print(f\"Match: {torch.allclose(result[0], manual)}\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Test 2: Some zero vectors\")\n",
    "    embeddings = torch.tensor([\n",
    "        [[1.0, 0.0], [0.0, 1.0], [0.0, 0.0], [1.0, 1.0]],  # One zero vector\n",
    "        [[1.0, 0.0], [0.0, 0.0], [0.0, 0.0], [0.0, 1.0]]   # Two zero vectors\n",
    "    ])\n",
    "    result = compute_avg_pairwise_sim(embeddings)\n",
    "    print(f\"Result: {result}\")\n",
    "    \n",
    "    # Manual verification for batch 0: vectors 0,1,3 are non-zero\n",
    "    # Pairs: (0,1)=0, (0,3)=1, (1,3)=1 -> avg = 2/3\n",
    "    v = embeddings[0][[0,1,3]]\n",
    "    sim = v @ v.T\n",
    "    manual = sim[~torch.eye(3, dtype=bool)].mean()\n",
    "    print(f\"Expected for batch 0: {manual}\")\n",
    "    print(f\"Match: {torch.allclose(result[0], manual)}\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Test 3: All zero vectors\")\n",
    "    embeddings = torch.zeros(2, 3, 5)\n",
    "    result = compute_avg_pairwise_sim(embeddings)\n",
    "    print(f\"Result (should be zeros): {result}\")\n",
    "    print(f\"All zeros: {torch.all(result == 0)}\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Test 4: Only one non-zero vector per batch\")\n",
    "    embeddings = torch.tensor([\n",
    "        [[1.0, 2.0], [0.0, 0.0], [0.0, 0.0]],\n",
    "        [[0.0, 0.0], [3.0, 4.0], [0.0, 0.0]]\n",
    "    ])\n",
    "    result = compute_avg_pairwise_sim(embeddings)\n",
    "    print(f\"Result (should be zeros - no pairs): {result}\")\n",
    "    print(f\"All zeros: {torch.all(result == 0)}\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Test 5: T=1 edge case\")\n",
    "    embeddings = torch.randn(2, 1, 5)\n",
    "    result = compute_avg_pairwise_sim(embeddings)\n",
    "    print(f\"Result for T=1: {result}\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Test 6: Differentiability test\")\n",
    "    embeddings = torch.tensor([\n",
    "        [[1.0, 2.0], [3.0, 4.0], [0.0, 0.0]]\n",
    "    ], requires_grad=True)\n",
    "    result = compute_avg_pairwise_sim(embeddings)\n",
    "    loss = result.sum()\n",
    "    loss.backward()\n",
    "    print(f\"Result: {result}\")\n",
    "    print(f\"Gradient shape: {embeddings.grad.shape}\")\n",
    "    print(f\"Gradient (should be non-zero for non-zero vectors):\\n{embeddings.grad}\")\n",
    "    print(f\"Zero vector gradient (should be zero): {embeddings.grad[0, 2]}\")\n",
    "    print(f\"Is differentiable: {embeddings.grad is not None}\\n\")\n",
    "    \n",
    "    \n",
    "    print(\"Test 7: Mixed scenario\")\n",
    "    embeddings = torch.tensor([\n",
    "        [[1.0, 0.0], [0.0, 1.0], [1.0, 1.0], [0.0, 0.0]],\n",
    "    ])\n",
    "    result = compute_avg_pairwise_sim(embeddings)\n",
    "    # Non-zero vectors: v0=[1,0], v1=[0,1], v2=[1,1]\n",
    "    # Similarities: v0·v1=0, v0·v2=1, v1·v2=1\n",
    "    # Average: (0 + 1 + 1) / 3 = 0.667\n",
    "    print(f\"Result: {result}\")\n",
    "    print(f\"Expected: ~0.667\")\n",
    "    print(f\"Match: {torch.allclose(result, torch.tensor([2/3]))}\\n\")\n",
    "\n",
    "test_compute_avg_pairwise_sim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2fe676fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 2])\n",
      "torch.Size([1, 3, 3])\n",
      "tensor([0.3333])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[[1, 2], [-2, 1], [-2, 1]]]).float()\n",
    "norma = F.normalize(a, dim=-1)\n",
    "print(a.shape)\n",
    "sim = norma @ norma.transpose(-1, -2)\n",
    "print(sim.shape)\n",
    "als = sim[:, ~torch.eye(sim.shape[1], dtype=bool)].mean(dim=1)\n",
    "print(als)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4c165b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9853])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09d78b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "als.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65594a85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([[  50.,  100.,  500.],\n",
       "        [ 100.,  200., 1000.],\n",
       "        [ 150.,  300., 1500.]]),\n",
       "indices=tensor([[0, 0, 0],\n",
       "        [1, 1, 1],\n",
       "        [2, 2, 2]]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries_embeddings = torch.tensor([\n",
    "    [[1.], [0.], [0.], [0.], [1]],\n",
    "    [[0.], [2.], [0.], [0.], [1]],\n",
    "    [[0.], [0.], [3.], [0.], [1]],\n",
    "])\n",
    "\n",
    "documents_embeddings = torch.tensor([   \n",
    "    [[50.], [5.], [1.]],\n",
    "    [[0.], [100.], [10.]],\n",
    "    [[1.], [0.], [500.]],\n",
    "])\n",
    "\n",
    "# documents_mask = torch.tensor([ \n",
    "#     [1., 1., 1.],\n",
    "#     [1., 0., 1.],\n",
    "#     [1., 1., 1.],\n",
    "# ])\n",
    "\n",
    "# query_mask = torch.tensor([\n",
    "#     [1., 1., 1., 1.], [1., 1., 1., 1.], [1., 1., 0., 1.]\n",
    "# ])\n",
    "\n",
    "scores = colbert_scores(\n",
    "    queries_embeddings=queries_embeddings,\n",
    "    documents_embeddings=documents_embeddings,\n",
    "    # queries_mask=query_mask,\n",
    "    # documents_mask=documents_mask,\n",
    ")\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab10102",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scaling2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
